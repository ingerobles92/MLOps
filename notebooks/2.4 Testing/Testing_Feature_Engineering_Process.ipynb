{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipytest in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (0.14.2)\n",
      "Requirement already satisfied: ipython in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipytest) (8.28.0)\n",
      "Requirement already satisfied: packaging in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipytest) (24.1)\n",
      "Requirement already satisfied: pytest>=5.4 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipytest) (8.3.3)\n",
      "Requirement already satisfied: iniconfig in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
      "Requirement already satisfied: colorama in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from pytest>=5.4->ipytest) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (2.18.0)\n",
      "Requirement already satisfied: stack-data in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from ipython->ipytest) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->ipytest) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from stack-data->ipython->ipytest) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from stack-data->ipython->ipytest) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from stack-data->ipython->ipytest) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\training\\itesm\\mlops_itesm\\practice3\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython->ipytest) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# This is needed only for the purpose of the notebook\n",
    "!pip install ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple setup in the data\n",
    "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the classes to build a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        # Each value is None when we instantiate the class\n",
    "        self.X_train, self.X_test, self.y_train, self.Y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Loading the dataset, and make the train, test, split.\"\"\"\n",
    "        dataset = datasets.load_iris()\n",
    "        \n",
    "        # Removing the units (cm) from the headers\n",
    "        self.feature_names = [fn[:-5] for fn in dataset.feature_names]\n",
    "        self.frame = pd.DataFrame(dataset.data, columns=self.feature_names)\n",
    "        self.frame['target'] = dataset.target\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.frame[self.feature_names], self.frame.target, test_size=0.65, random_state=42)\n",
    "        \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        \n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        return self.model.predict(input_data)\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Execution method for running the pipeline several times.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineWithFeatureEngineering(SimplePipeline):\n",
    "    def __init__(self):\n",
    "        # Calling the inherit method SimplePipeline __init__ first.\n",
    "        super().__init__()\n",
    "        \n",
    "        # Standardizing the variables in the dataset.\n",
    "        self.scaler = StandardScaler()\n",
    "        # Training the pipeline\n",
    "        self.scaler.fit(self.X_train)\n",
    "    \n",
    "    def apply_scaler(self):\n",
    "        # Scaling training and testing data with mean 0 and variance 1.\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        # Applying the scaler before making the predictions.\n",
    "        scaled_input_data = self.scaler.transform(input_data)\n",
    "        return self.model.predict(scaled_input_data)\n",
    "                  \n",
    "    def run_pipeline(self):\n",
    "        self.load_dataset()\n",
    "        self.apply_scaler()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the model is: 0.9591836734693877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Training\\ITESM\\MLOps_ITESM\\practice3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = PipelineWithFeatureEngineering()\n",
    "pipeline.run_pipeline()\n",
    "accuracy_score = pipeline.get_accuracy()\n",
    "print(f'The Accuracy of the model is: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def pipeline():\n",
    "    pl = PipelineWithFeatureEngineering()\n",
    "    pl.load_dataset()\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..                                                                                           [100%]\n",
      "2 passed in 0.43s\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_mean_near_zero(pipeline):\n",
    "    original_mean = pipeline.X_train.stack().mean()\n",
    "    \n",
    "    pipeline.apply_scaler()\n",
    "    \n",
    "    assert original_mean > pipeline.X_train.mean()\n",
    "    assert np.isclose(pipeline.X_train.mean(), 0.0, atol=1e-3)\n",
    "\n",
    "    print(f'The mean of the original X train is: {original_mean}')\n",
    "    print(f'The mean of the transformed X train is: {pipeline.X_train.mean()}')\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_std_near_one(pipeline):\n",
    "    pipeline.apply_scaler()\n",
    "    \n",
    "    assert np.isclose(pipeline.X_train.std(), 1.0, atol=1e-3)\n",
    "    print(f'The SD of the transformed X train is : {pipeline.X_train.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the tests fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F                                                                                            [100%]\n",
      "============================================ FAILURES =============================================\n",
      "_____________________ test_scaler_preprocessing_brings_x_train_mean_near_zero _____________________\n",
      "\n",
      "pipeline = <__main__.PipelineWithDataEngineering object at 0x000001C183E5A210>\n",
      "\n",
      "    def test_scaler_preprocessing_brings_x_train_mean_near_zero(pipeline):\n",
      "        original_mean = pipeline.X_train.stack().mean()\n",
      "    \n",
      "        pipeline.apply_scaler()\n",
      "    \n",
      "        # Cambiamos la aserción para que falle\n",
      ">       assert original_mean < pipeline.X_train.mean()\n",
      "E       assert 3.5889423076923075 < -5.978123978750843e-17\n",
      "E        +  where -5.978123978750843e-17 = <built-in method mean of numpy.ndarray object at 0x000001C183EDB870>()\n",
      "E        +    where <built-in method mean of numpy.ndarray object at 0x000001C183EDB870> = array([[ 0.04967733, -2.13501958,  0.56638299,  0.24421145],\\n       [ 1.52580366,  0.49581023,  1.16990584,  0.6583091...    [-0.19634373, -1.08268765, -0.03713987, -0.16988623],\\n       [ 1.40279314, -0.03035573,  1.10955356,  1.07240681]]).mean\n",
      "E        +      where array([[ 0.04967733, -2.13501958,  0.56638299,  0.24421145],\\n       [ 1.52580366,  0.49581023,  1.16990584,  0.6583091...    [-0.19634373, -1.08268765, -0.03713987, -0.16988623],\\n       [ 1.40279314, -0.03035573,  1.10955356,  1.07240681]]) = <__main__.PipelineWithDataEngineering object at 0x000001C183E5A210>.X_train\n",
      "\n",
      "C:\\Users\\richv\\AppData\\Local\\Temp\\ipykernel_35552\\243239845.py:7: AssertionError\n",
      "===================================== short test summary info =====================================\n",
      "FAILED t_7024752a2a704a8cb6e79e32ba12a1da.py::test_scaler_preprocessing_brings_x_train_mean_near_zero - assert 3.5889423076923075 < -5.978123978750843e-17\n",
      "1 failed in 2.81s\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_mean_near_zero(pipeline):\n",
    "    original_mean = pipeline.X_train.stack().mean()\n",
    "    \n",
    "    pipeline.apply_scaler()\n",
    "\n",
    "    # Changing the assertion, so it will fail\n",
    "    assert original_mean < pipeline.X_train.mean()\n",
    "\n",
    "    # Changing the value in isclose to make it fail\n",
    "    assert not np.isclose(pipeline.X_train.mean(), 1.0, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m______________________ test_scaler_preprocessing_brings_x_train_std_near_one ______________________\u001b[0m\n",
      "\n",
      "pipeline = <__main__.PipelineWithDataEngineering object at 0x000002A4464BAE10>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_scaler_preprocessing_brings_x_train_std_near_one\u001b[39;49;00m(pipeline):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Adding huge variation in the data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        pipeline.X_train *= \u001b[94m1000\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        pipeline.apply_scaler()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Testing with the original tolerance\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m np.isclose(pipeline.X_train.std(), \u001b[94m1.0\u001b[39;49;00m, atol=\u001b[94m1e-3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert np.False_\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where np.False_ = <function isclose at 0x000002A427256230>(np.float64(2933.821906997921), 1.0, atol=0.001)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function isclose at 0x000002A427256230> = np.isclose\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   np.float64(2933.821906997921) = <built-in method std of numpy.ndarray object at 0x000002A4464A9950>()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where <built-in method std of numpy.ndarray object at 0x000002A4464A9950> = array([[ 7373.30072401,  5779.90273544,  3015.16304958,  2068.66212188],\\n       [ 8849.42705968,  8410.7325448 ,  3618...32.23465918,  2411.6401934 ,  1654.56444212],\\n       [ 8726.41653171,  7884.56658292,  3558.33362013,  2896.85748142]]).std\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +        where array([[ 7373.30072401,  5779.90273544,  3015.16304958,  2068.66212188],\\n       [ 8849.42705968,  8410.7325448 ,  3618...32.23465918,  2411.6401934 ,  1654.56444212],\\n       [ 8726.41653171,  7884.56658292,  3558.33362013,  2896.85748142]]) = <__main__.PipelineWithDataEngineering object at 0x000002A4464BAE10>.X_train\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\richv\\AppData\\Local\\Temp\\ipykernel_13876\\3289142395.py\u001b[0m:8: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_a213d9986eb742eda4c104357aeb6655.py::\u001b[1mtest_scaler_preprocessing_brings_x_train_std_near_one\u001b[0m - assert np.False_\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 1.20s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scaler_preprocessing_brings_x_train_std_near_one(pipeline):\n",
    "    # Adding huge variation in the data\n",
    "    pipeline.X_train *= 1000\n",
    "\n",
    "    pipeline.apply_scaler()\n",
    "\n",
    "    # Testing with the original tolerance\n",
    "    assert np.isclose(pipeline.X_train.std(), 1.0, atol=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
